{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter \n",
    "import colorsys\n",
    "import itertools\n",
    "import pickle \n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import fcsparser\n",
    "import fcswrite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader, PdfFileMerger\n",
    "import io\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import ot\n",
    "\n",
    "from scipy.spatial import distance, ConvexHull\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mutual_info_score, normalized_mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "import fcsparser \n",
    "from ete3 import Tree, TreeNode, TreeStyle, TextFace\n",
    "\n",
    "from utils import *\n",
    "\n",
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Supplementary Data into FCS Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for cell type 9587\n",
      "Writing data for cell type 9589\n",
      "Writing data for cell type 9590\n",
      "Writing data for cell type 9591\n",
      "Writing data for cell type 9592\n",
      "Writing data for cell type 9593\n",
      "Writing data for cell type 9595\n",
      "Writing data for cell type 9596\n",
      "Writing data for cell type 9597\n",
      "Writing data for cell type 9600\n",
      "Writing data for cell type 9601\n",
      "Writing data for cell type 9602\n",
      "Writing data for cell type 9604\n",
      "Writing data for cell type 9605\n",
      "Writing data for cell type 9606\n",
      "Writing data for cell type 9607\n",
      "Writing data for cell type 9608\n",
      "Writing data for cell type 9609\n",
      "Writing data for cell type 9611\n",
      "Writing data for cell type 9613\n",
      "Writing data for cell type 9614\n",
      "Writing data for cell type 9615\n",
      "Writing data for cell type 9617\n",
      "Writing data for cell type 9618\n",
      "Writing data for cell type 9619\n",
      "Writing data for cell type 9620\n",
      "Writing data for cell type 9626\n",
      "Writing data for cell type 9628\n",
      "Writing data for cell type 9629\n",
      "Writing data for cell type 9632\n",
      "Writing data for cell type 9635\n",
      "Writing data for cell type 9637\n",
      "Writing data for cell type 9638\n",
      "Writing data for cell type 9639\n",
      "Writing data for cell type 9640\n",
      "Writing data for cell type 9641\n",
      "Writing data for cell type 9643\n",
      "Writing data for cell type 9644\n"
     ]
    }
   ],
   "source": [
    "supplementary_data = pd.read_csv('../Suppl.Table2.CODEX_paper_MRLdatasetexpression.csv')\n",
    "marker_cols = list(supplementary_data.columns[1:30])\n",
    "supplementary_data = supplementary_data[marker_cols + ['Imaging phenotype cluster ID']]\n",
    "ids_to_names = pd.read_csv('ClusterIDtoName.txt', sep='\\t')\n",
    "cell_lines = list(ids_to_names['ID'].values)\n",
    "ids_to_names = dict(zip(ids_to_names['ID'].values, ids_to_names['Name'].values))\n",
    "# remove dirt from supplementary data \n",
    "supplementary_annotations = pd.read_excel('../Suppl.Table2.cluster annotations and cell counts.xlsx')\n",
    "exclude = supplementary_annotations.loc[\n",
    "                                     supplementary_annotations['Imaging phenotype (cell type)'] == 'dirt',\n",
    "                                     'X-shift cluster ID']\n",
    "supplementary_data = supplementary_data[~supplementary_data['Imaging phenotype cluster ID'].isin(exclude)]\n",
    "suppl_groupby = supplementary_data.groupby('Imaging phenotype cluster ID')\n",
    "if not os.path.isdir('scaffold_landmarks'):\n",
    "    os.mkdir('scaffold_landmarks')\n",
    "for cell_id, data in suppl_groupby:\n",
    "    print('Writing data for cell type', cell_id)\n",
    "    fcswrite.write_fcs(filename='scaffold_landmarks/cell_{}.fcs'.format(cell_id), \n",
    "                       chn_names=list(data.columns), \n",
    "                       data=data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Vite on Cell Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD45', 'Ly6C', 'TCR', 'Ly6G', 'CD19', 'CD169', 'CD106', 'CD3', 'CD1632', 'CD8a', 'CD90', 'F480', 'CD11c', 'Ter119', 'CD11b', 'IgD', 'CD27', 'CD5', 'CD79b', 'CD71', 'CD31', 'CD4', 'IgM', 'B220', 'ERTR7', 'CD35', 'CD2135', 'CD44', 'NKp46']\n"
     ]
    }
   ],
   "source": [
    "# write clusters of tree to FCS files \n",
    "tree = pickle.load(open('tree_combined_for_html.pkl', 'rb'))\n",
    "supplementary_data = pd.read_csv('../Suppl.Table2.CODEX_paper_MRLdatasetexpression.csv')\n",
    "marker_cols = list(supplementary_data.columns[1:30])\n",
    "supplementary_data.rename(columns={'X.X': 'X', 'Y.Y': 'Y', 'Z.Z': 'Z'}, inplace=True)\n",
    "supplementary_data['CD45_int'] = supplementary_data['CD45'].astype(int)\n",
    "ids_to_names = pd.read_csv('ClusterIDtoName.txt', sep='\\t')\n",
    "cell_lines = list(ids_to_names['ID'].values)\n",
    "ids_to_names = dict(zip(ids_to_names['ID'].values, ids_to_names['Name'].values))\n",
    "# remove dirt from supplementary data \n",
    "supplementary_annotations = pd.read_excel('../Suppl.Table2.cluster annotations and cell counts.xlsx')\n",
    "dirt = supplementary_annotations.loc[supplementary_annotations['Imaging phenotype (cell type)'] == 'dirt', \n",
    "                                     'X-shift cluster ID']\n",
    "supplementary_data = supplementary_data[~supplementary_data['Imaging phenotype cluster ID'].isin(dirt)]\n",
    "supplementary_data['sample'] = supplementary_data['sample_Xtile_Ytile'].apply(lambda x: x.split('_')[0])\n",
    "suppl_converted = convert_coordinates(supplementary_data)[['X', 'Y', 'Z', 'sample'] + marker_cols]\n",
    "print(marker_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing layer 0\n",
      "Writing layer 1\n",
      "Writing layer 2\n",
      "Writing layer 3\n",
      "Writing layer 4\n",
      "Writing layer 5\n",
      "Writing layer 6\n",
      "Writing layer 7\n",
      "Writing layer 8\n",
      "Writing layer 9\n",
      "Writing layer 10\n",
      "Writing layer 11\n",
      "Writing layer 12\n",
      "Writing layer 13\n",
      "Writing layer 14\n",
      "Writing layer 15\n",
      "Writing layer 16\n",
      "Writing layer 17\n",
      "Writing layer 18\n",
      "Writing layer 19\n",
      "Writing layer 20\n",
      "Writing layer 21\n",
      "Writing layer 22\n",
      "Writing layer 23\n",
      "Writing layer 24\n",
      "Writing layer 25\n",
      "Writing layer 26\n",
      "Writing layer 27\n",
      "Writing layer 28\n",
      "Writing layer 29\n",
      "Writing layer 30\n",
      "Writing layer 31\n",
      "Writing layer 32\n",
      "Writing layer 33\n",
      "Writing layer 34\n",
      "Writing layer 35\n",
      "Writing layer 36\n",
      "Writing layer 37\n",
      "Writing layer 38\n",
      "Writing layer 39\n",
      "Writing layer 40\n",
      "Writing layer 41\n"
     ]
    }
   ],
   "source": [
    "def write_layers(tree):\n",
    "    layers = get_layers(tree)\n",
    "    for layer_ind, layer in enumerate(layers):\n",
    "        print('Writing layer', layer_ind)\n",
    "        layer_dir = 'scaffold_analysis/Layer_' + str(layer_ind)\n",
    "        if not os.path.exists(layer_dir):\n",
    "            os.makedirs(layer_dir)\n",
    "        all_clusters_markers = []\n",
    "        for cluster_ind, node in enumerate(layer):\n",
    "            node_markers= pd.merge(node.coords, suppl_converted, how='inner', on=['X', 'Y', 'Z', 'sample'])\n",
    "            node_markers = node_markers[marker_cols].mean()\n",
    "            all_clusters_markers.append(node_markers)\n",
    "        all_clusters_markers = pd.DataFrame(all_clusters_markers)\n",
    "        all_clusters_markers.to_csv(layer_dir + '/clusters_avg_markers.txt', sep='\\t', index=False)\n",
    "            \n",
    "write_layers(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suppl_converted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2ee57d8d6d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree_combined_for_html.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_layer_intersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-2ee57d8d6d74>\u001b[0m in \u001b[0;36mget_layer_intersection\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmost_intersect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppl_converted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppl_converted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Imaging phenotype cluster ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'suppl_converted' is not defined"
     ]
    }
   ],
   "source": [
    "def get_layer_intersection(layer):\n",
    "    # for layer of tree, get cell types that each nodes intersects with most \n",
    "    most_intersect = []\n",
    "    for node in layer:\n",
    "        overlap = pd.merge(node.coords, suppl_converted, on=['X', 'Y', 'Z', 'sample'], how='inner')\n",
    "        print(node.coords.shape[0], suppl_converted.shape[0], overlap.shape[0])\n",
    "        counts = overlap['Imaging phenotype cluster ID'].value_counts().to_dict()\n",
    "        most_intersect_node = max(counts, key=counts.get)\n",
    "        most_intersect.append(most_intersect_node)\n",
    "        \n",
    "    return most_intersect \n",
    "\n",
    "tree = pickle.load(open('tree_combined_for_html.pkl', 'rb'))\n",
    "for layer in get_layers(tree):\n",
    "    print(get_layer_intersection(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/lib/python3.6/site-packages/rpy2/ipython/rmagic.py:73: UserWarning: The Python package 'pandas' is stronglyrecommended when using `rpy2.ipython`. Unfortunately it could not be loaded, but at least we found 'numpy'.\n",
      "  \"but at least we found 'numpy'.\")))\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
