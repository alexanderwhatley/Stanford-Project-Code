{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter \n",
    "import colorsys\n",
    "import itertools\n",
    "import pickle \n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import fcsparser\n",
    "import fcswrite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader, PdfFileMerger\n",
    "import io\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import ot\n",
    "\n",
    "from scipy.spatial import distance, ConvexHull\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mutual_info_score, normalized_mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "import fcsparser \n",
    "from ete3 import Tree, TreeNode, TreeStyle, TextFace, add_face_to_node\n",
    "\n",
    "from utils import *\n",
    "\n",
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Supplementary Data into FCS Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for cell type B cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for cell type B220(+) DN T cells\n",
      "Writing data for cell type CD106(+)CD16.32(+)CD31(+) stroma\n",
      "Writing data for cell type CD106(+)CD16.32(+)CD31(-)Ly6C(-) stroma\n",
      "Writing data for cell type CD106(+)CD16.32(-)Ly6C(+)CD31(+)\n",
      "Writing data for cell type CD106(-)CD16.32(+)Ly6C(+)CD31(-)\n",
      "Writing data for cell type CD106(-)CD16.32(-)Ly6C(+)CD31(+) stroma\n",
      "Writing data for cell type CD11c(+) B cells\n",
      "Writing data for cell type CD3(+) other markers (-)\n",
      "Writing data for cell type CD31(hi) vascular\n",
      "Writing data for cell type CD4(+) T cells\n",
      "Writing data for cell type CD4(+)CD8(-)cDC\n",
      "Writing data for cell type CD4(+)MHCII(+)\n",
      "Writing data for cell type CD4(-)CD8(+)cDC\n",
      "Writing data for cell type CD4(-)CD8(-) cDC\n",
      "Writing data for cell type CD8(+) T cells\n",
      "Writing data for cell type ERTR7(+) stroma\n",
      "Writing data for cell type F4.80(+) mphs\n",
      "Writing data for cell type FDCs\n",
      "Writing data for cell type NK cells\n",
      "Writing data for cell type capsule\n",
      "Writing data for cell type erythroblasts\n",
      "Writing data for cell type granulocytes\n",
      "Writing data for cell type marginal zone macrophages\n",
      "Writing data for cell type megakaryocytes\n",
      "Writing data for cell type noid\n",
      "Writing data for cell type plasma cells\n"
     ]
    }
   ],
   "source": [
    "supplementary_data = pd.read_csv('../Suppl.Table2.CODEX_paper_MRLdatasetexpression.csv')\n",
    "marker_cols = list(supplementary_data.columns[1:30])\n",
    "supplementary_data = supplementary_data[marker_cols + ['Imaging phenotype cluster ID']]\n",
    "ids_to_names = pd.read_csv('ClusterIDtoName.txt', sep='\\t')\n",
    "cell_lines = list(ids_to_names['ID'].values)\n",
    "ids_to_names = dict(zip(ids_to_names['ID'].values, ids_to_names['Name'].values))\n",
    "# remove dirt from supplementary data \n",
    "supplementary_annotations = pd.read_excel('../Suppl.Table2.cluster annotations and cell counts.xlsx')\n",
    "exclude = supplementary_annotations.loc[\n",
    "                                     supplementary_annotations['Imaging phenotype (cell type)'] == 'dirt',\n",
    "                                     'X-shift cluster ID']\n",
    "supplementary_data = supplementary_data[~supplementary_data['Imaging phenotype cluster ID'].isin(exclude)]\n",
    "supplementary_data['Imaging phenotype cluster ID'] = supplementary_data['Imaging phenotype cluster ID'].apply(lambda x: ids_to_names[x].replace('/', '.'))\n",
    "suppl_groupby = supplementary_data.groupby('Imaging phenotype cluster ID')\n",
    "if not os.path.isdir('scaffold_landmarks'):\n",
    "    os.mkdir('scaffold_landmarks')\n",
    "for cell_id, data in suppl_groupby:\n",
    "    print('Writing data for cell type', cell_id)\n",
    "    data.drop('Imaging phenotype cluster ID', axis=1, inplace=True)\n",
    "    fcswrite.write_fcs(filename='scaffold_landmarks/cell_{}.fcs'.format(cell_id), \n",
    "                       chn_names=list(data.columns), \n",
    "                       data=data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Vite on Cell Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD45', 'Ly6C', 'TCR', 'Ly6G', 'CD19', 'CD169', 'CD106', 'CD3', 'CD1632', 'CD8a', 'CD90', 'F480', 'CD11c', 'Ter119', 'CD11b', 'IgD', 'CD27', 'CD5', 'CD79b', 'CD71', 'CD31', 'CD4', 'IgM', 'B220', 'ERTR7', 'CD35', 'CD2135', 'CD44', 'NKp46']\n"
     ]
    }
   ],
   "source": [
    "# write clusters of tree to FCS files \n",
    "tree = pickle.load(open('tree_combined_for_html.pkl', 'rb'))\n",
    "supplementary_data = pd.read_csv('../Suppl.Table2.CODEX_paper_MRLdatasetexpression.csv')\n",
    "marker_cols = list(supplementary_data.columns[1:30])\n",
    "supplementary_data.rename(columns={'X.X': 'X', 'Y.Y': 'Y', 'Z.Z': 'Z'}, inplace=True)\n",
    "supplementary_data['CD45_int'] = supplementary_data['CD45'].astype(int)\n",
    "ids_to_names = pd.read_csv('ClusterIDtoName.txt', sep='\\t')\n",
    "cell_lines = list(ids_to_names['ID'].values)\n",
    "ids_to_names = dict(zip(ids_to_names['ID'].values, ids_to_names['Name'].values))\n",
    "# remove dirt from supplementary data \n",
    "supplementary_annotations = pd.read_excel('../Suppl.Table2.cluster annotations and cell counts.xlsx')\n",
    "dirt = supplementary_annotations.loc[supplementary_annotations['Imaging phenotype (cell type)'] == 'dirt', \n",
    "                                     'X-shift cluster ID']\n",
    "supplementary_data = supplementary_data[~supplementary_data['Imaging phenotype cluster ID'].isin(dirt)]\n",
    "supplementary_data['sample'] = supplementary_data['sample_Xtile_Ytile'].apply(lambda x: x.split('_')[0])\n",
    "supplementary_data['Imaging phenotype cluster ID'] = supplementary_data['Imaging phenotype cluster ID'].apply(lambda x: ids_to_names[x].replace('/', '.'))\n",
    "suppl_converted = convert_coordinates(supplementary_data)[['X', 'Y', 'Z', 'sample', 'Imaging phenotype cluster ID']\n",
    "                                                          + marker_cols]\n",
    "del supplementary_data\n",
    "print(marker_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing layer 0\n",
      "Writing layer 1\n",
      "Writing layer 2\n",
      "Writing layer 3\n",
      "Writing layer 4\n",
      "Writing layer 5\n",
      "Writing layer 6\n",
      "Writing layer 7\n",
      "Writing layer 8\n",
      "Writing layer 9\n",
      "Writing layer 10\n",
      "Writing layer 11\n",
      "Writing layer 12\n",
      "Writing layer 13\n",
      "Writing layer 14\n",
      "Writing layer 15\n",
      "Writing layer 16\n",
      "Writing layer 17\n",
      "Writing layer 18\n",
      "Writing layer 19\n",
      "Writing layer 20\n",
      "Writing layer 21\n",
      "Writing layer 22\n",
      "Writing layer 23\n",
      "Writing layer 24\n",
      "Writing layer 25\n",
      "Writing layer 26\n",
      "Writing layer 27\n",
      "Writing layer 28\n",
      "Writing layer 29\n",
      "Writing layer 30\n",
      "Writing layer 31\n",
      "Writing layer 32\n",
      "Writing layer 33\n",
      "Writing layer 34\n",
      "Writing layer 35\n",
      "Writing layer 36\n",
      "Writing layer 37\n",
      "Writing layer 38\n",
      "Writing layer 39\n",
      "Writing layer 40\n",
      "Writing layer 41\n"
     ]
    }
   ],
   "source": [
    "def write_layers(tree):\n",
    "    layers = get_layers(tree)\n",
    "    for layer_ind, layer in enumerate(layers):\n",
    "        print('Writing layer', layer_ind)\n",
    "        layer_dir = 'scaffold_analysis/Layer_' + str(layer_ind)\n",
    "        if not os.path.exists(layer_dir):\n",
    "            os.makedirs(layer_dir)\n",
    "        all_clusters_markers = []\n",
    "        for cluster_ind, node in enumerate(layer):\n",
    "            node_markers= pd.merge(node.coords, suppl_converted, how='inner', on=['X', 'Y', 'Z', 'sample'])\n",
    "            node_markers = node_markers[marker_cols].mean()\n",
    "            all_clusters_markers.append(node_markers)\n",
    "        all_clusters_markers = pd.DataFrame(all_clusters_markers)\n",
    "        all_clusters_markers[all_clusters_markers < 0] = 0\n",
    "        all_clusters_markers['cellType'] = ['Cluster_' + str(i) for i in range(all_clusters_markers.shape[0])]\n",
    "        all_clusters_markers.to_csv(layer_dir + '/clusters_avg_markers.txt', sep='\\t', index=False)\n",
    "            \n",
    "write_layers(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_clusters_to_types(tree, save=True):\n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    ts.rotation = 90\n",
    "    def my_layout(node):\n",
    "        F = TextFace(node.name, tight_text=True)\n",
    "        F.rotation = 270\n",
    "        add_face_to_node(F, node, column=0, position=\"branch-right\")\n",
    "        F.border.width = 1\n",
    "        F.inner_border.width = 1\n",
    "    ts.layout_fn = my_layout\n",
    "    \n",
    "    annotated_tree = recreate_tree(tree, color=False)\n",
    "    layers = get_layers(annotated_tree)\n",
    "    for layer_ind, layer in enumerate(layers):\n",
    "        graph_filename = 'scaffold_result/Layer_{}/clusters_avg_markers.txt.graphml'.format(layer_ind)\n",
    "        graph = nx.read_graphml(graph_filename)\n",
    "        nodes_clusters = [(node, data) for node, data in graph.nodes(data=True) if data['cellType'].startswith('Cluster_')]\n",
    "        converter = {node: data['cellType'] for node, data in graph.nodes(data=True)}\n",
    "        nodes_landmark = set([node for node, data in graph.nodes(data=True) if not data['cellType'].startswith('Cluster_')])\n",
    "        cluster_types = {}\n",
    "        for node, data in nodes_clusters:\n",
    "            max_weight_node, max_weight_val = None, None\n",
    "            for neighbor, edge_data in graph[node].items():\n",
    "                if neighbor in nodes_landmark:\n",
    "                    if max_weight_val is None or edge_data['weight'] > max_weight_val:\n",
    "                        max_weight_node = neighbor\n",
    "                        max_weight_val = edge_data['weight']\n",
    "            cluster_types[converter[node]] = converter[max_weight_node]\n",
    "        for ind, node in enumerate(layer):\n",
    "            node.add_features(name=cluster_types['Cluster_' + str(ind)])\n",
    "    if save:       \n",
    "        annotated_tree.render('matched_tree.pdf', tree_style=ts)\n",
    "    else:\n",
    "        return annotated_tree.render('%%inline', tree_style=ts)\n",
    "    \n",
    "match_clusters_to_types(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_intersection(layer):\n",
    "    # for layer of tree, get cell types that each nodes intersects with most \n",
    "    most_intersect = {}\n",
    "    for ind, node in enumerate(layer):\n",
    "        overlap = pd.merge(node.coords, suppl_converted, on=['X', 'Y', 'Z', 'sample'], how='inner')\n",
    "        counts = overlap['Imaging phenotype cluster ID'].value_counts().to_dict()\n",
    "        most_intersect_node = max(counts, key=counts.get)\n",
    "        most_intersect['Cluster_' + str(ind)] = most_intersect_node\n",
    "        \n",
    "    return most_intersect \n",
    "\n",
    "def max_overlap_to_types(tree, save=True):\n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    ts.rotation = 90\n",
    "    def my_layout(node):\n",
    "        F = TextFace(node.name, tight_text=True)\n",
    "        F.rotation = 270\n",
    "        add_face_to_node(F, node, column=0, position=\"branch-right\")\n",
    "        F.border.width = 1\n",
    "        F.inner_border.width = 1\n",
    "    ts.layout_fn = my_layout\n",
    "    \n",
    "    annotated_tree = recreate_tree(tree, color=False)\n",
    "    orig_layers = get_layers(tree)\n",
    "    new_layers = list(get_layers(annotated_tree))   \n",
    "    for layer_ind, layer in enumerate(orig_layers):\n",
    "        cluster_types = get_layer_intersection(layer)\n",
    "        for ind, node in enumerate(new_layers[layer_ind]):\n",
    "            node.add_features(name=cluster_types['Cluster_' + str(ind)])\n",
    "            \n",
    "    if save:       \n",
    "        annotated_tree.render('overlap_labeled_tree.pdf', tree_style=ts)\n",
    "    else:\n",
    "        return annotated_tree.render('%%inline', tree_style=ts)\n",
    "    \n",
    "max_overlap_to_types(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
